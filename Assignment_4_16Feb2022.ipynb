{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78d5cfe8",
   "metadata": {},
   "source": [
    "### Q 1. Scrape the details of most viewed videos on YouTube from Wikipedia. \n",
    "### Url = https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos \n",
    "### You need to find following details:\n",
    "<ul>\n",
    "<li>A) Rank \n",
    "<li>B) Name \n",
    "<li>C) Artist \n",
    "<li>D) Upload date \n",
    "<li>E) Views\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c5c9d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17563202",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(r'C:\\temp\\chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8542096d",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de2677c",
   "metadata": {},
   "outputs": [],
   "source": [
    "zzz = []\n",
    "names = []\n",
    "links = []\n",
    "ranks = []\n",
    "authors = []\n",
    "views = []\n",
    "dates = []\n",
    "search_job = driver.find_elements_by_xpath('//*[@id=\"mw-content-text\"]/div[1]/table[3]/tbody/tr')\n",
    "#len(search_job)\n",
    "for i in search_job:\n",
    "    try:\n",
    "        ranks.append(i.find_element_by_xpath('.//td[1]').text)\n",
    "    except:\n",
    "        ranks.append('--NA--')\n",
    "\n",
    "    \n",
    "    try:\n",
    "        names.append(i.find_element_by_xpath('.//td[2]').text)\n",
    "    except:\n",
    "        names.append('--NA--')\n",
    "    try:\n",
    "        links.append(i.find_element_by_xpath('.//td[2]/sup/a').text)\n",
    "    except:\n",
    "        links.append('--NA--')        \n",
    "\n",
    "    try:\n",
    "        zzz.append(i.find_element_by_xpath('.//td[2]/a').text)\n",
    "    except:\n",
    "        zzz.append('--NA--')\n",
    "\n",
    "        \n",
    "    try:\n",
    "        authors.append(i.find_element_by_xpath('.//td[3]').text)\n",
    "    except:\n",
    "        authors.append('--NA--')\n",
    "\n",
    "    try:\n",
    "        views.append(i.find_element_by_xpath('.//td[4]').text)\n",
    "    except:\n",
    "        views.append('--NA--')\n",
    "    try:\n",
    "        dates.append(i.find_element_by_xpath('.//td[5]').text)\n",
    "    except:\n",
    "        dates.append('--NA--')\n",
    "        \n",
    "        \n",
    "for i in range(0, len(names)):\n",
    "    #print(i)\n",
    "    names[i]=names[i].replace(links[i],'')\n",
    "        \n",
    "df = pd.DataFrame();\n",
    "df['Rank']=ranks\n",
    "df['Name']=names\n",
    "df['Author']=authors\n",
    "#df['RankLink']=links\n",
    "#df['Link']= zzz\n",
    "df['Upload Date'] = dates\n",
    "df['Views']= views\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4510358",
   "metadata": {},
   "source": [
    "### Q. 2. Scrape the details team Indiaâ€™s international fixtures from bcci.tv. \n",
    "### Url = https://www.bcci.tv/. \n",
    "### You need to find following details: \n",
    "<ul>\n",
    "<li>A) Match title (I.e. 1st ODI) \n",
    "<li>B) Series \n",
    "<li>C) Place \n",
    "<li>D) Date \n",
    "<li>E) Time \n",
    "</ul>\n",
    "Note: - From bcci.tv home page you have reach to the international fixture page through code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53209b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.bcci.tv/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d9f2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "btn_international = driver.find_element_by_xpath('//*[@id=\"navigation\"]/ul[1]/li[2]/a');\n",
    "btn_international.click();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712ce77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "match_title = []\n",
    "match = driver.find_elements_by_xpath('//*[@id=\"fixtures\"]/div[3]/div[1]/div[1]/div/div[4]/div/span[2]')\n",
    "for i in match:\n",
    "    print (\":::\",i.tag_name,\":\", i.text)\n",
    "#     for j in i.find_elements_by_xpath('.//*'):\n",
    "#         print(\"    ----\", j.tag_name, \":\", j.text)\n",
    "    #break;\n",
    "    \n",
    "# for i in match:\n",
    "#     match_title.append(i.find_element_by_xpath('.//div/div/div[3]').text)\n",
    "#match_title\n",
    "#for i in match:\n",
    "    #for j in i.find_elements_by_xpath('.'):\n",
    "#    print (i.tag_name, \":\", i.text)\n",
    "#break\n",
    "odis = []\n",
    "places = []\n",
    "series = []\n",
    "dates = []\n",
    "times = []\n",
    "match = driver.find_elements_by_xpath('//*[@id=\"fixtures\"]/div[3]/div[1]/div') #[1]\n",
    "for i in match:\n",
    "    \n",
    "    try:\n",
    "        odis.append(i.find_element_by_xpath('.//div/div[4]/div/span[1]').text)\n",
    "    except:\n",
    "        odis.append('-NA-')\n",
    "    \n",
    "    try:\n",
    "        places.append(i.find_element_by_xpath('.//div/div[4]/div/span[2]').text)\n",
    "    except:\n",
    "        places.append(i.find_element_by_xpath('.//div/div[4]/div').text)\n",
    "        \n",
    "    try:\n",
    "        series.append(i.find_element_by_xpath('.//div/div[1]/h5[2]/span').text)\n",
    "    except:\n",
    "        series.append('--NA--')\n",
    "\n",
    "    try:\n",
    "        dates.append(i.find_element_by_xpath('.//div/div[1]/div/div[1]').text)\n",
    "    except:\n",
    "        dates.append('--NA--')\n",
    "    try:\n",
    "        times.append(i.find_element_by_xpath('.//div/div[1]/div/div[2]').text)\n",
    "    except:\n",
    "        times.append('--NA--')\n",
    "        \n",
    "df = pd.DataFrame()\n",
    "df['ODI'] = odis\n",
    "df['Place']= places\n",
    "df['Series']= series\n",
    "df['Date']= dates\n",
    "df['Time']=times\n",
    "df\n",
    "    #print('match:', odi, \"  place:\", name,\"  Series:\", sname)    # ('.//div/div[4]/div/span[2]').text)\n",
    "#len(match)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e3fae1a",
   "metadata": {},
   "source": [
    "### Scrape the details of selenium exception from guru99.com. \n",
    "### Url = https://www.guru99.com/ \n",
    "### You need to find following details:\n",
    "<ul>\n",
    "<li>A) Name \n",
    "<li>B) Description \n",
    "</ul>\n",
    "\n",
    "### Note: - From guru99 home page you have to reach to selenium exception handling page through code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79887cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.guru99.com/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15289850",
   "metadata": {},
   "outputs": [],
   "source": [
    "btn = driver.find_element_by_xpath('//*[@id=\"java_technologies\"]/li[3]/a')\n",
    "btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dfeb9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "btn0=  driver.find_element_by_xpath('//*[@id=\"cbox\"]/div/div/div/div/div[1]')\n",
    "btn0.click()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22449c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "btn1= driver.find_element_by_xpath('//*[@id=\"post-193\"]/div/div/table[5]/tbody/tr[34]/td[1]/a')\n",
    "btn1.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ad2509",
   "metadata": {},
   "outputs": [],
   "source": [
    "expn = []\n",
    "desc = []\n",
    "for i in driver.find_elements_by_xpath('//*[@id=\"post-1953\"]/div/div/table/tbody/tr'):\n",
    "    #for j in i.find_elements_by_xpath('.//td'):\n",
    "    try:\n",
    "        expn.append(i.find_elements_by_xpath('.//td')[0].text)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        desc.append(i.find_elements_by_xpath('.//td')[1].text)\n",
    "    except:\n",
    "        pass\n",
    "df = pd.DataFrame()\n",
    "df['Exception'] = expn\n",
    "df['Description'] = desc\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e7fa28",
   "metadata": {},
   "source": [
    "### Scrape the details of State-wise GDP of India from statisticstime.com. \n",
    "### Url = http://statisticstimes.com/ \n",
    "### You have to find following details:\n",
    "<ul>\n",
    "<li>A) Rank \n",
    "<li>B) State \n",
    "<li>C) GSDP \n",
    "<li>D) GSDP \n",
    "<li>E) Share \n",
    "<li>F) GDP($ billion) \n",
    "</ul>\n",
    "\n",
    "### Note: - From statisticstimes home page you have to reach to economy page through code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da4388d",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://statisticstimes.com/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af7ca4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "url2 = driver.find_element_by_xpath('//*[@id=\"top\"]/div[2]/div[2]/div/a[3]').get_attribute('href')\n",
    "driver.get(url2)\n",
    "url2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99186338",
   "metadata": {},
   "outputs": [],
   "source": [
    "url3 = driver.find_element_by_xpath('/html/body/div[2]/div[2]/div[2]/ul/li[1]/a').get_attribute('href')\n",
    "driver.get(url3)\n",
    "url3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d8a9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranks = []\n",
    "states = []\n",
    "gsdp1 = []\n",
    "gsdp2 = []\n",
    "shares = []\n",
    "gdps = []\n",
    "for i in driver.find_elements_by_xpath('//*[@id=\"table_id\"]/tbody/tr'):\n",
    "    ranks.append(i.find_element_by_xpath('.//td[1]').text)\n",
    "    states.append(i.find_element_by_xpath('.//td[2]').text)\n",
    "    try:\n",
    "        gsdp1.append(i.find_element_by_xpath('.//td[3]').text)\n",
    "    except:\n",
    "        gsdp1.append('-')\n",
    "    try:\n",
    "        gsdp2.append(i.find_element_by_xpath('.//td[4]').text)\n",
    "    except:\n",
    "        gsdp2.append('-')\n",
    "    try:\n",
    "        shares.append(i.find_element_by_xpath('.//td[5]').text)\n",
    "    except:\n",
    "        shares.append('-')\n",
    "    try:\n",
    "        gdps.append(i.find_element_by_xpath('.//td[6]').text)\n",
    "    except:\n",
    "        gdps.append('-')\n",
    "\n",
    "        \n",
    "df = pd.DataFrame()\n",
    "df['Rank'] = ranks\n",
    "df['State'] = states\n",
    "df['GSDP1'] = gsdp1\n",
    "df['GSDP2'] = gsdp2\n",
    "df['Share'] = shares\n",
    "df['GDP'] =gdps\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892b41e3",
   "metadata": {},
   "source": [
    "### Q.5. Scrape the details of trending repositories on Github.com. \n",
    "### Url = https://github.com/ \n",
    "### You have to find the following details: \n",
    "<ul>\n",
    "<li>A) Repository title \n",
    "<li>B) Repository description \n",
    "<li>C) Contributors count \n",
    "<li>D) Language used \n",
    "</ul>\n",
    "\n",
    "### Note: - From the home page you have to click on the trending option from Explore menu through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1049afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://github.com/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b82ee35",
   "metadata": {},
   "outputs": [],
   "source": [
    "url1 = driver.find_element_by_xpath('/html/body/div[1]/header/div/div[2]/nav/ul/li[4]/details/div/ul/li[5]/a').get_attribute('href')\n",
    "driver.get(url1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc65e575",
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = []\n",
    "descriptions = []\n",
    "members = []\n",
    "langs = []\n",
    "for i in driver.find_elements_by_xpath('//*[@id=\"js-pjax-container\"]/div[3]/div/div[2]/article'):  #('//*[@id=\"js-pjax-container\"]/div[3]/div/div[2]/article[1]/h1/a/span'):\n",
    "    titles.append(i.find_element_by_xpath('.//h1/a').text)\n",
    "    try:\n",
    "        descriptions.append(i.find_element_by_xpath('.//p').text)\n",
    "    except:\n",
    "        descriptions.append('-NA-')\n",
    "    try:\n",
    "        members.append(i.find_element_by_xpath('.//div[2]/a[2]').text)\n",
    "    except:\n",
    "        members.append('-NA-')\n",
    "    try:\n",
    "        langs.append(i.find_element_by_xpath('.//div[2]/span[1]/span[2]').text)\n",
    "    except:\n",
    "        langs.append('-NA-')\n",
    "        \n",
    "df = pd.DataFrame()\n",
    "df['Title']= titles\n",
    "df['Description'] =  descriptions\n",
    "df[\"Member Count\"] = members\n",
    "df['Language'] = langs\n",
    "df\n",
    "#'//*[@id=\"js-pjax-container\"]/div[3]/div/div[2]/article[1]/h1/a'\n",
    "#'//*[@id=\"js-pjax-container\"]/div[3]/div/div[2]/article[1]/p'\n",
    "#'//*[@id=\"js-pjax-container\"]/div[3]/div/div[2]/article[1]/div[2]/a[2]'\n",
    "#'//*[@id=\"js-pjax-container\"]/div[3]/div/div[2]/article[1]/div[2]/span[1]/span[2]'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a02b7a0",
   "metadata": {},
   "source": [
    "### Q. 6.  Scrape the details of top 100 songs on billiboard.com. \n",
    "### Url =  https:/www.billboard.com/ \n",
    "### You have to find the following details: \n",
    "<ul>\n",
    "<li>A) Song name \n",
    "<li>B) Artist name \n",
    "<li>C) Last week rank \n",
    "<li>D) Peak rank \n",
    "<li>E) Weeks on board\n",
    "</ul>\n",
    "\n",
    "### Note: - From the home page you have to click on the charts option then hot 100-page link through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65810141",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://www.billboard.com/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987cf30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "btn = driver.find_element_by_xpath('//*[@id=\"main-wrapper\"]/header/div[1]/div/div/div[2]/div/nav/ul/li[1]/a')\n",
    "btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7014df",
   "metadata": {},
   "outputs": [],
   "source": [
    "btn = driver.find_element_by_xpath('//*[@id=\"main-wrapper\"]/header/div[2]/div/nav/ul/li[1]/a')\n",
    "btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1a7005",
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = []\n",
    "artists = []\n",
    "lwrnk = []\n",
    "peak = []\n",
    "onboard = []\n",
    "for i in driver.find_elements_by_xpath('//*[@id=\"post-1479786\"]/div[3]/div/div/div/div[2]/div[@class=\"o-chart-results-list-row-container\"]'):\n",
    "    try:\n",
    "        titles.append(i.find_element_by_xpath('.//*[@id=\"title-of-a-story\"]').text)\n",
    "    except:\n",
    "        titles.append('-NA-')\n",
    "        \n",
    "    try:\n",
    "        artists.append(i.find_element_by_xpath('.//ul/li[4]/ul/li[1]/span').text)\n",
    "    except:\n",
    "        artists.append('-NA-')\n",
    "    try:\n",
    "        lwrnk.append(i.find_element_by_xpath('.//ul/li[4]/ul/li[4]/span').text)\n",
    "    except:\n",
    "        lwrnk.append('-NA-')\n",
    "    try:\n",
    "        peak.append(i.find_element_by_xpath('.//ul/li[4]/ul/li[5]/span').text)\n",
    "    except:\n",
    "        peak.append('-NA-')\n",
    "        \n",
    "    try:\n",
    "        onboard.append(i.find_element_by_xpath('.//ul/li[4]/ul/li[6]/span').text)\n",
    "    except:\n",
    "        onboard.appedn('-NA-')\n",
    "        \n",
    "df = pd.DataFrame()\n",
    "df['Title'] = titles\n",
    "df['Artists'] = artists\n",
    "df['Last Week Rank']= lwrnk\n",
    "df['Peak Rank']=peak\n",
    "df['On Board'] = onboard\n",
    "df.head()\n",
    "#'//*[@id=\"title-of-a-story\"]'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc1b708",
   "metadata": {},
   "source": [
    "### Q. 7.  Scrape the details of Data science recruiters from naukri.com. \n",
    "### Url = https://www.naukri.com/ \n",
    "### You have to find the following details: \n",
    "<ul>\n",
    "<li>A) Name \n",
    "<li>B) Designation \n",
    "<li>C) Company \n",
    "<li>D) Skills they hire for \n",
    "<li>E) Location\n",
    "</ul>\n",
    "\n",
    "### Note: - From naukri.com homepage click on the recruiters option and the on the search pane type Data science and \n",
    "### click on search. All this should be done through code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa843146",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.naukri.com/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172e21f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = driver.find_element_by_xpath('//*[@id=\"root\"]/div[2]/div[3]/div/div/div[1]/div/div/div/input')\n",
    "inp.send_keys('Data Science')\n",
    "btn = driver.find_element_by_xpath('//*[@id=\"root\"]/div[2]/div[3]/div/div/div[6]')\n",
    "btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a771c54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "link2 = driver.find_element_by_xpath('//*[@id=\"root\"]/div[1]/div/ul[1]/li[2]/div/ul/li[1]/a').get_attribute('href')\n",
    "driver.get(link2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059d567a",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp2 = driver.find_element_by_xpath('//*[@id=\"skill\"]/div[1]/div[2]/input')\n",
    "inp2.send_keys('Data Science')\n",
    "#loc = driver.find_element_by_xpath('//*[@id=\"location\"]/div[1]/div[2]/input')\n",
    "#loc.send_keys('Delhi/NCR')\n",
    "btn = driver.find_element_by_xpath('//*[@id=\"qsbFormBtn\"]')\n",
    "btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b265af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = []\n",
    "design = []\n",
    "comp = []\n",
    "skills = []\n",
    "locs = []\n",
    "for i in driver.find_elements_by_xpath('//*[@id=\"tabP-1\"]/div'):\n",
    "    names.append(i.find_element_by_xpath('.//div[1]/div[1]/div[1]/p/a[1]/span').text)\n",
    "    names.append(i.find_element_by_xpath('.//div[2]/div[1]/div[1]/p/a[1]/span').text)\n",
    "\n",
    "    design.append(i.find_element_by_xpath('.//div[1]/div[1]/div[1]/p/span[1]').text)\n",
    "    design.append(i.find_element_by_xpath('.//div[2]/div[1]/div[1]/p/span[1]').text)\n",
    "\n",
    "    comp.append( i.find_element_by_xpath('.//div[1]/div[1]/div[1]/p/a[2]').text)\n",
    "    comp.append( i.find_element_by_xpath('.//div[2]/div[1]/div[1]/p/a[2]').text)\n",
    "                  \n",
    "    skills.append(i.find_element_by_xpath('.//div[1]/div[1]/div[2]').text)    \n",
    "    skills.append(i.find_element_by_xpath('.//div[2]/div[1]/div[2]').text)\n",
    "    \n",
    "    try:\n",
    "        locs.append(i.find_element_by_xpath('.//div[1]/div[1]/div[1]/p/span[2]').text)\n",
    "    except:\n",
    "        locs.append('-NA-')\n",
    "    try:\n",
    "        locs.append(i.find_element_by_xpath('.//div[2]/div[1]/div[1]/p/span[2]').text)\n",
    "    except:\n",
    "        locs.append('-NA-')\n",
    "    \n",
    "df = pd.DataFrame()\n",
    "df['Name']=names\n",
    "df['Designation']= design\n",
    "df['Company'] = comp\n",
    "df['Skills'] = skills\n",
    "df['Location']=locs\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d71e13e0",
   "metadata": {},
   "source": [
    "### 8. Scrape the details of Highest selling novels. \n",
    "#### Url = https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare/ \n",
    "### You have to find the following details: \n",
    "<ul>\n",
    "<li>A) Book name \n",
    "<li>B) Author name \n",
    "<li>C) Volumes sold \n",
    "<li>D) Publisher \n",
    "<li>E) Genre\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88cfd061",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d6fa5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranks = []\n",
    "names = []\n",
    "volumes = []\n",
    "publishers = []\n",
    "genres = [] \n",
    "for i in driver.find_elements_by_xpath('//*[@id=\"article-body-blocks\"]/div/table/tbody/tr'):\n",
    "    ranks.append(i.find_element_by_xpath('.//td[1]').text)\n",
    "    names.append(i.find_element_by_xpath('.//td[2]').text)\n",
    "    volumes.append(i.find_element_by_xpath('.//td[4]').text)\n",
    "    publishers.append(i.find_element_by_xpath('.//td[5]').text)\n",
    "    genres.append(i.find_element_by_xpath('.//td[6]').text)\n",
    "    \n",
    "df = pd.DataFrame()\n",
    "df['Rank']= ranks\n",
    "df['Name']=names\n",
    "df['Volumes Sold']=volumes\n",
    "df['Publisher']=publishers\n",
    "df['Genre'] = genres\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ee2e2a",
   "metadata": {},
   "source": [
    "### Q. 9. Scrape the details most watched tv series of all time from imdb.com. \n",
    "### Url =  https://www.imdb.com/list/ls095964455/ \n",
    "### You have to find the following details: \n",
    "<ul>\n",
    "<li>A) Name \n",
    "<li>B) Year span \n",
    "<li>C) Genre \n",
    "<li>D) Run time \n",
    "<li>E) Ratings \n",
    "<li>F) Votes\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6404f867",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.imdb.com/list/ls095964455/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27070ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = []\n",
    "years = []\n",
    "genres = []\n",
    "rtimes = []\n",
    "ratings =[]\n",
    "votes=[]\n",
    "for i in driver.find_elements_by_xpath('//*[@id=\"main\"]/div/div[3]/div[3]/div'):\n",
    "    names.append(i.find_element_by_xpath('.//div[2]/h3/a').text)\n",
    "    years.append(i.find_element_by_xpath('.//div[2]/h3/span[2]').text)\n",
    "    genres.append(i.find_element_by_xpath('.//div[2]/p[1]/span[5]').text)\n",
    "    rtimes.append(i.find_element_by_xpath('.//div[2]/p[1]/span[3]').text)\n",
    "    ratings.append(i.find_element_by_xpath('.//div[2]/div[1]/div[1]/span[2]').text)\n",
    "    votes.append(i.find_element_by_xpath('//div[2]/p[4]/span[2]').text)\n",
    "df = pd.DataFrame()\n",
    "df['Name']=names\n",
    "df['Years']=years\n",
    "df['Genre']=genres\n",
    "df['Run Time']= rtimes\n",
    "df['Ratings']= ratings\n",
    "df['Votes']=votes\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16717e0",
   "metadata": {},
   "source": [
    "### Q. 10. Details of Datasets from UCI machine learning repositories. \n",
    "### Url = https://archive.ics.uci.edu/ \n",
    "### You have to find the following details: \n",
    "<ul>\n",
    "<li>A) Dataset name \n",
    "<li>B) Data type \n",
    "<li>C) Task \n",
    "<li>D) Attribute type \n",
    "<li>E) No of instances \n",
    "<li>F) No of attribute \n",
    "<li>G) Year\n",
    "</ul>\n",
    "\n",
    "#### Note: - from the home page you have to go to the ShowAllDataset page through code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e375bd44",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://archive.ics.uci.edu/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb3e1430",
   "metadata": {},
   "outputs": [],
   "source": [
    "lnk = driver.find_element_by_xpath('/html/body/table[1]/tbody/tr/td[2]/span[2]/a')\n",
    "lnk.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ec3da8dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Data Type</th>\n",
       "      <th>Task</th>\n",
       "      <th>Attribute Type</th>\n",
       "      <th>No of Instances</th>\n",
       "      <th>No of Attributes</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abalone</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>4177</td>\n",
       "      <td>8</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adult</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td>48842</td>\n",
       "      <td>14</td>\n",
       "      <td>1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Annealing</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>798</td>\n",
       "      <td>38</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Anonymous Microsoft Web Data</td>\n",
       "      <td></td>\n",
       "      <td>Recommender-Systems</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>37711</td>\n",
       "      <td>294</td>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Name      Data Type                  Task  \\\n",
       "0                         Abalone  Multivariate        Classification    \n",
       "1                           Adult  Multivariate        Classification    \n",
       "2                       Annealing  Multivariate        Classification    \n",
       "3    Anonymous Microsoft Web Data                 Recommender-Systems    \n",
       "\n",
       "                Attribute Type No of Instances No of Attributes   Year  \n",
       "0  Categorical, Integer, Real            4177                8   1995   \n",
       "1        Categorical, Integer           48842               14   1996   \n",
       "2  Categorical, Integer, Real             798               38          \n",
       "3                 Categorical           37711              294   1998   "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names = []\n",
    "dtypes = []\n",
    "tasks = []\n",
    "attribs = []\n",
    "instances=[]\n",
    "noofattribs=[]\n",
    "years=[]\n",
    "counter = 0\n",
    "\n",
    "for i in driver.find_elements_by_xpath('/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr'):\n",
    "    counter+=1\n",
    "    if counter==1:\n",
    "        continue\n",
    "        \n",
    "    if counter==6:\n",
    "        break\n",
    "        \n",
    "    try:\n",
    "        names.append(     i.find_element_by_xpath('./td[1]').text)\n",
    "    except:\n",
    "        names.append('-NA-')\n",
    "        \n",
    "    dtypes.append     (i.find_element_by_xpath('./td[2]/p').text)\n",
    "    tasks.append      (i.find_element_by_xpath('./td[3]/p').text)\n",
    "    attribs.append    (i.find_element_by_xpath('./td[4]/p').text)\n",
    "    instances.append  (i.find_element_by_xpath('./td[5]/p').text)\n",
    "    noofattribs.append(i.find_element_by_xpath('./td[6]/p').text)\n",
    "    years.append      (i.find_element_by_xpath('./td[7]/p').text)\n",
    "    \n",
    "df = pd.DataFrame()\n",
    "df['Name']=names\n",
    "df['Data Type']=dtypes\n",
    "df['Task']=tasks\n",
    "df['Attribute Type']=attribs\n",
    "df['No of Instances']=instances\n",
    "df['No of Attributes']=noofattribs\n",
    "df['Year']= years\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbdebf87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46688cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
